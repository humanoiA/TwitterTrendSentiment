{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy=pd.read_csv('training.1600000.processed.noemoticon.csv',sep=',',header = None,skiprows=100,encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    799900\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:][0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.columns[1:5],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['body',\n",
       " 'of',\n",
       " 'miss',\n",
       " 'northern',\n",
       " 'calif',\n",
       " 'girl',\n",
       " 'found',\n",
       " 'police',\n",
       " 'have',\n",
       " 'found',\n",
       " 'the',\n",
       " 'remains',\n",
       " 'of',\n",
       " 'a',\n",
       " 'miss',\n",
       " 'northern',\n",
       " 'california',\n",
       " 'girl']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watching  '"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Body Of Missing Northern Calif. Girl Found: Police have found the remains of a missing Northern California girl .. '"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.loc[:][5])):\n",
    "    df.at[i,5]=re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", df.loc[i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.loc[:][5])):\n",
    "    df.at[i,5]=re.sub(r\"&[^\\s]*;\",\"\", df.loc[i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watching  '"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"&[^\\s]*;\",\"\",df.loc[3][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Body',\n",
       " 'Of',\n",
       " 'Missing',\n",
       " 'Northern',\n",
       " 'Calif',\n",
       " 'Girl',\n",
       " 'Found',\n",
       " 'Police',\n",
       " 'have',\n",
       " 'found',\n",
       " 'the',\n",
       " 'remains',\n",
       " 'of',\n",
       " 'a',\n",
       " 'missing',\n",
       " 'Northern',\n",
       " 'California',\n",
       " 'girl']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "tokenizer.tokenize(df.loc[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.loc[:][5])):\n",
    "    #final_data.title[i]=tokenizer.tokenize(final_data.title[i])\n",
    "    df.at[i,5]=tokenizer.tokenize(df.at[i,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "import string\n",
    "from nltk import pos_tag,word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lmtzr = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poop'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df=df\n",
    "dummy_df.loc[88][5][5]='poop'\n",
    "dummy_df.loc[88][5][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.loc[:][5])):\n",
    "    #for j in range(len(final_data.title[i])):\n",
    "        #final_data.title[i][j]=lmtzr.lemmatize(final_data.title[i][j].lower())\n",
    "    for j in range(len(df.loc[i][5][:])):\n",
    "        for word, tag in pos_tag(word_tokenize(df.loc[i][5][j].lower())):\n",
    "             wntag = tag[0].lower()\n",
    "             wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "             if not wntag:\n",
    "                 lemma = word\n",
    "             else:\n",
    "                 lemma = lmtzr.lemmatize(word, wntag)\n",
    "        #print(dummy_df.description[i][j])\n",
    "        df.loc[i][5][j]=lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "vectorizer1 = CountVectorizer(stop_words='english')\n",
    "vectorizer2 = TfidfVectorizer(stop_words='english')\n",
    "#for i in range(len(df.loc[:][5])):\n",
    "    #df.at[i,5] = \" \".join(df.loc[i][5])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          body of miss northern calif girl found police ...\n",
       "1          i hope they will increase the capacity fast ye...\n",
       "2                                behind on my class for work\n",
       "3                                                      watch\n",
       "4          remember my bum leg strike back this time its ...\n",
       "                                 ...                        \n",
       "1599895    just woke up have no school be the best feel ever\n",
       "1599896      thewdb com very cool to hear old walt interview\n",
       "1599897    be you ready for your mojo makeover ask me for...\n",
       "1599898    happy th birthday to my boo of alll time tupac...\n",
       "1599899                                 happy charitytuesday\n",
       "Name: 5, Length: 1599900, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shubh\\anaconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df.loc[0][5]=\" \".join(df.loc[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1071933, 193351)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "x_train_count = count_vectorizer.fit_transform(x_train)\n",
    "x_train_count.shape\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "x_train_tfidf = tfidf.fit_transform(x_train_count)\n",
    "x_train_tfidf.shape\n",
    "\n",
    "#fv=vectorizer2.fit_transform(df.loc[:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.loc[:][5], df.loc[:][0],\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=df.loc[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import  Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(x_train_tfidf, y_train)\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "\n",
    "text_clf = text_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 0, ..., 0, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = text_clf.predict(x_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7693416444588392\n",
      "0.7692783388621155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "accuracy = accuracy_score(y_test,predictions)\n",
    "print(accuracy)\n",
    "\n",
    "f1 = f1_score(y_test,predictions,average='weighted')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM score it is: 0.7443217989749341\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('cvec', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42))])\n",
    "text_clf_svm = text_clf_svm.fit(x_train, y_train)\n",
    "predictions_svm = text_clf_svm.predict(x_test)\n",
    "\n",
    "f1_score_svm = f1_score(y_test, predictions_svm, average = 'weighted')\n",
    "print(f'SVM score it is: {f1_score_svm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('cv', CountVectorizer()),\n",
      "                                       ('model', MultinomialNB())]),\n",
      "             param_grid={'cv__stop_words': [['and', 'is']]})\n",
      "{'cv__stop_words': ['and', 'is']}\n",
      "Train Score:  0.7763\n",
      "Train Score:  0.7773\n"
     ]
    }
   ],
   "source": [
    "model_mult_nb = MultinomialNB()\n",
    "pipe1 = Pipeline([('cv',count_vectorizer),\n",
    "                ('model',model_mult_nb)\n",
    "])\n",
    "params = {'cv__stop_words': [['and','is',]]}\n",
    "gs = GridSearchCV(pipe1,param_grid=params, cv=5)\n",
    "print(gs.fit(x_train,y_train))\n",
    "print(gs.best_params_)\n",
    "print(\"Train Score: \", round(gs.best_score_,4))\n",
    "print(\"Train Score: \", round(gs.score(x_test,y_test),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = count_vectorizer.fit_transform(x_train)\n",
    "X_test_vec = count_vectorizer.transform(x_test)\n",
    "rf = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "rf.fit(X_train_vec,y_train)\n",
    "print(\"Cross Val Score: \",cross_val_score(rf,X_train_vec,y_train,cv=5).mean())\n",
    "print(\"Train Score: \", round(rf.score(X_train_vec,y_train),4))\n",
    "print(\"Train Score: \", round(rf.score(X_test_vec,y_test),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf.predict(X_test_vec)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "f1 = f1_score(y_test,y_pred,average='weighted')\n",
    "print(f1)\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB(fit_prior=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=False)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7544827612331831"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_str(user_post):\n",
    "    user_post=re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", user_post)\n",
    "    user_post=re.sub(r\"&[^\\s]*;\",\"\",user_post)\n",
    "    user_post=tokenizer.tokenize(user_post)\n",
    "    for i in range(len(user_post)):\n",
    "        for word, tag in pos_tag(word_tokenize(user_post[i].lower())):\n",
    "             wntag = tag[0].lower()\n",
    "             wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "             if not wntag:\n",
    "                 lemma = word\n",
    "             else:\n",
    "                 lemma = lmtzr.lemmatize(word, wntag)\n",
    "        #print(dummy_df.description[i][j])\n",
    "        user_post[i]=lemma\n",
    "    return \" \".join(user_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i be very angry at my teacher he kick me out of class'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_str('I am very angry at my teacher. he kicked me out of class.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599895</th>\n",
       "      <td>4</td>\n",
       "      <td>just woke up have no school be the best feel ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599896</th>\n",
       "      <td>4</td>\n",
       "      <td>thewdb com very cool to hear old walt interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599897</th>\n",
       "      <td>4</td>\n",
       "      <td>be you ready for your mojo makeover ask me for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599898</th>\n",
       "      <td>4</td>\n",
       "      <td>happy th birthday to my boo of alll time tupac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599899</th>\n",
       "      <td>4</td>\n",
       "      <td>happy charitytuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  5\n",
       "1599895  4  just woke up have no school be the best feel ever\n",
       "1599896  4    thewdb com very cool to hear old walt interview\n",
       "1599897  4  be you ready for your mojo makeover ask me for...\n",
       "1599898  4  happy th birthday to my boo of alll time tupac...\n",
       "1599899  4                               happy charitytuesday"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=df2.append({5:parse_str('i was very surprised when i saw her very happy in her new attire.')},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          body of miss northern calif girl found police ...\n",
       "1          i hope they will increase the capacity fast ye...\n",
       "2                                behind on my class for work\n",
       "3                                                      watch\n",
       "4          remember my bum leg strike back this time its ...\n",
       "                                 ...                        \n",
       "1599896      thewdb com very cool to hear old walt interview\n",
       "1599897    be you ready for your mojo makeover ask me for...\n",
       "1599898    happy th birthday to my boo of alll time tupac...\n",
       "1599899                                 happy charitytuesday\n",
       "1599900    i be very surprised when i saw her very happy ...\n",
       "Name: 5, Length: 1599901, dtype: object"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.loc[:][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv2=vectorizer2.transform(test_data.loc[:][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4], dtype=int64)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b=fv2.shape\n",
    "model.predict(fv2[a-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile=open('imputed_data.sav','rb')\n",
    "#new_mod = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599895</th>\n",
       "      <td>4</td>\n",
       "      <td>just woke up have no school be the best feel ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599896</th>\n",
       "      <td>4</td>\n",
       "      <td>thewdb com very cool to hear old walt interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599897</th>\n",
       "      <td>4</td>\n",
       "      <td>be you ready for your mojo makeover ask me for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599898</th>\n",
       "      <td>4</td>\n",
       "      <td>happy th birthday to my boo of alll time tupac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599899</th>\n",
       "      <td>4</td>\n",
       "      <td>happy charitytuesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  5\n",
       "1599895  4  just woke up have no school be the best feel ever\n",
       "1599896  4    thewdb com very cool to hear old walt interview\n",
       "1599897  4  be you ready for your mojo makeover ask me for...\n",
       "1599898  4  happy th birthday to my boo of alll time tupac...\n",
       "1599899  4                               happy charitytuesday"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
